{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import logging\n",
    "import urllib.error\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getLogger(dir):\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger()\n",
    "    # create a file handler\n",
    "    handler = logging.FileHandler(fileDir+'/getNYTData.log')\n",
    "    handler.setLevel(logging.INFO)\n",
    "    # create a logging format\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    handler.setFormatter(formatter)\n",
    "    # add the handlers to the logger\n",
    "    logger.addHandler(handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helpful function to figure out what to name individual JSON files        \n",
    "def getJSONName(date, page, json_file_path):\n",
    "    json_file_name = \".\".join([date,str(page),'json'])\n",
    "    json_file_name = \"\".join([json_file_path,json_file_name])\n",
    "    return json_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to iterate through dates\n",
    "def getDays( start_date, end_date ):\n",
    "    if start_date <= end_date:\n",
    "        for n in range( ( end_date - start_date ).days + 1 ):\n",
    "            yield start_date + datetime.timedelta( n )\n",
    "    else:\n",
    "        for n in range( ( start_date - end_date ).days + 1 ):\n",
    "            yield start_date - datetime.timedelta( n )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getArticles(date, api_key, json_file_path):\n",
    "    # LOOP THROUGH THE 101 PAGES NYTIMES ALLOWS FOR THAT DATE\n",
    "    for page in range(100):\n",
    "        try:\n",
    "            request_string = \"http://api.nytimes.com/svc/search/v2/articlesearch.json?q=Presidential+Election+donald+trump+hillary+clinton&begin_date=\" + date + \"&end_date=\" + date + \"&page=\" + str(page) + \"&api-key=\" + api_key\n",
    "            response = urllib.request.urlopen(request_string)\n",
    "            content = response.read().decode('utf-8')\n",
    "            if content:\n",
    "                articles = json.loads(content)\n",
    "                # if there are articles here\n",
    "                if len(articles[\"response\"][\"docs\"]) >= 1:\n",
    "                    json_file_name = getJSONName(date, page, json_file_path)\n",
    "                    json_file = open(json_file_name, 'w')\n",
    "                    json_file.write(content)\n",
    "                    json_file.close()\n",
    "                # if no more articles, go to next date\n",
    "                else:\n",
    "                    time.sleep(3)\n",
    "                    return\n",
    "            time.sleep(3)\n",
    "        except: \n",
    "            logger.error(\"Error on %s page %s: %s\", date, file_number, sys.exc_info()[0])\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Getting started.\n",
      "INFO:root:Working on 20160701.\n",
      "INFO:root:Working on 20160702.\n",
      "INFO:root:Working on 20160703.\n",
      "INFO:root:Working on 20160704.\n",
      "INFO:root:Working on 20160705.\n",
      "INFO:root:Working on 20160706.\n",
      "INFO:root:Working on 20160707.\n",
      "INFO:root:Working on 20160708.\n",
      "INFO:root:Working on 20160709.\n",
      "INFO:root:Working on 20160710.\n",
      "INFO:root:Working on 20160711.\n",
      "INFO:root:Working on 20160712.\n",
      "INFO:root:Working on 20160713.\n",
      "INFO:root:Working on 20160714.\n",
      "INFO:root:Working on 20160715.\n",
      "INFO:root:Working on 20160716.\n",
      "INFO:root:Working on 20160717.\n",
      "INFO:root:Working on 20160718.\n",
      "INFO:root:Working on 20160719.\n",
      "INFO:root:Working on 20160720.\n",
      "INFO:root:Working on 20160721.\n",
      "INFO:root:Working on 20160722.\n",
      "INFO:root:Working on 20160723.\n",
      "INFO:root:Working on 20160724.\n",
      "INFO:root:Working on 20160725.\n",
      "INFO:root:Working on 20160726.\n",
      "INFO:root:Working on 20160727.\n",
      "INFO:root:Working on 20160728.\n",
      "INFO:root:Working on 20160729.\n",
      "INFO:root:Working on 20160730.\n",
      "INFO:root:Working on 20160731.\n",
      "INFO:root:Working on 20160801.\n",
      "INFO:root:Working on 20160802.\n",
      "INFO:root:Working on 20160803.\n",
      "INFO:root:Working on 20160804.\n",
      "INFO:root:Working on 20160805.\n",
      "INFO:root:Working on 20160806.\n",
      "INFO:root:Working on 20160807.\n",
      "INFO:root:Working on 20160808.\n",
      "INFO:root:Working on 20160809.\n",
      "INFO:root:Working on 20160810.\n",
      "INFO:root:Working on 20160811.\n",
      "INFO:root:Working on 20160812.\n",
      "INFO:root:Working on 20160813.\n",
      "INFO:root:Working on 20160814.\n",
      "INFO:root:Working on 20160815.\n",
      "INFO:root:Working on 20160816.\n",
      "INFO:root:Working on 20160817.\n",
      "INFO:root:Working on 20160818.\n",
      "INFO:root:Working on 20160819.\n",
      "INFO:root:Working on 20160820.\n",
      "INFO:root:Working on 20160821.\n",
      "INFO:root:Working on 20160822.\n",
      "INFO:root:Working on 20160823.\n",
      "ERROR:root:Unexpected error: <class 'NameError'>\n",
      "INFO:root:Finished.\n"
     ]
    }
   ],
   "source": [
    "# Main function where stuff gets done\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "logger = getLogger(fileDir)\n",
    "json_file_path = fileDir+'\\\\data\\\\'\n",
    "api_key = os.environ['nyc_api_key']\n",
    "start = datetime.date( year = 2016, month = 7, day = 1 )\n",
    "end = datetime.date( year = 2016, month = 8, day = 30 )\n",
    "\n",
    "logging.info(\"Getting started.\") \n",
    "try:\n",
    "    # LOOP THROUGH THE SPECIFIED DATES\n",
    "    for date in getDays( start, end ):\n",
    "        date = date.strftime(\"%Y%m%d\")\n",
    "        logging.info(\"Working on %s.\" % date)\n",
    "        getArticles(date, api_key, json_file_path)\n",
    "except:\n",
    "    logging.error(\"Unexpected error: %s\", str(sys.exc_info()[0]))\n",
    "finally:\n",
    "    logging.info(\"Finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
